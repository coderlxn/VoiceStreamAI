import tornado.ioloop
import tornado.web
import logging
import asyncio
import os
import time
import random
import string
import base64
import openai
from openai import AsyncOpenAI
import torch
from TTS.api import TTS
from src.asr.asr_factory import ASRFactory


class VoiceChatRequest(tornado.web.RequestHandler):

    def __init__(self, *args, **kwargs):
        super(VoiceChatRequest, self).__init__(*args, **kwargs)
        self.set_header('Content-Type', 'text/event-stream')
        self.set_header('Access-Control-Allow-Origin', "*")
        self.set_header("Access-Control-Allow-Headers", "*")
        # è¯·æ±‚æ–¹å¼
        self.set_header("Access-Control-Allow-Methods", "*")

        self.base_url = os.environ.get("OPENAI_BASE_URL")

    async def write_message(self, key):
        for idx in range(10):
            val = {"code": 200, "msg": "success", "data": f"{key} {idx}"}
            self.write(f'data:{val}\n\n')
            await self.flush()
            await asyncio.sleep(3)
        await asyncio.sleep(1)
        return ''

    async def get_chat_response_sync(self, messages) -> str:
        start = time.time()
        logging.debug("å¼€å§‹GPTè¯·æ±‚")
        try:
            client = AsyncOpenAI(base_url=self.base_url)
            completion = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages
            )
            logging.debug("syncGPT è€—æ—¶2 = {:.3f}".format(time.time() - start))
            result = (await completion).choices[0].message.content
            logging.info(f'request {messages} \nchat response {result}')
            logging.debug("GPTè¯·æ±‚å®Œæˆ è€—æ—¶3 = {:.3f}".format(time.time() - start))
            return result
        except Exception as e:
            return repr(e)

    async def post(self):
        logging.info('new post request connect')
        # æ¥æ”¶æ–‡ä»¶
        if 'file' not in self.request.files:
            val = {"code": 400, "msg": 'file is required'}
            self.write(f'data:{val}\n\n')
            await self.flush()
            return

        tts_source = self.request.headers.get('tts_source')

        file = self.request.files['file'][0]
        # logging.debug(f'file received {file}')
        original_fname = file['filename']
        extension = os.path.splitext(original_fname)[1]
        fname = ''.join(random.choice(string.ascii_lowercase + string.digits) for x in range(6))
        final_filename = fname + extension
        file_path = final_filename
        output_file = open(file_path, 'wb')
        output_file.write(file['body'])
        if not os.path.exists(file_path):
            logging.warning('audio file save failed')
            val = {"code": 400, "msg": 'audio file save failed'}
            self.write(f'data:{val}\n\n')
            await self.flush()
            return

        # è§£æéŸ³é¢‘åˆ°æ–‡å­—
        start = time.time()
        transcription = await asr_pipeline.transcribe_file(file_path, None)
        if 'text' in transcription and transcription['text'] != '':
            end = time.time()
            text = transcription["text"]
            logging.debug(f'è§£æåˆ°å£°éŸ³å†…å®¹ï¼š {text}ï¼Œ è€—æ—¶: {end - start}')

            messages = [{"role": "user", "content": text}]
            content = await self.get_chat_response_sync(messages)
            val = {"code": 200, "msg": 'success', 'text': content}
            self.write(f'data:{val}\n\n')
            await self.flush()

            target_file = f"speech{random.randint(1000, 9999)}.wav"
            tts.tts_to_file(text=content, speaker_wav="/root/TTS/tests/data/ljspeech/wavs/LJ001-0001.wav",
                            language="zh-cn", file_path=target_file)
            if not os.path.exists(target_file):
                logging.warning('convert text to speech failed')
                val = {"code": 500, "msg": 'convert text to speech failed'}
                self.write(f'data:{val}\n\n')
                return

            with open(target_file, mode='rb') as f:
                byte_array = f.read()
                bytes_str = base64.b64encode(byte_array).decode('utf-8')
                val = {"code": 200, "msg": 'success', 'audio': bytes_str}
                self.write(f'data:{val}\n\n')
                await self.flush()
            # åˆ æ‰ä¸´æ—¶æ–‡ä»¶
            # os.remove(target_file)

            # client = openai.OpenAI()
            # response = client.audio.speech.create(
            #     model="tts-1",
            #     voice="alloy",
            #     input=content,
            # )

            # for data in response.iter_bytes():
            #     # logging.debug(f'speech component: {data}')
            #     bytes_str = base64.b64encode(data).decode('utf-8')
            #     val = {"code": 200, "msg": 'success', 'audio': bytes_str}
            #     self.write(f'data:{val}\n\n')
            #     await self.flush()


def make_app():
    return tornado.web.Application([
        (r"/cogen/v1/voice_chat", VoiceChatRequest)
    ])


if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)

    app = make_app()

    asr_args = {"model_size": "large-v3"}
    asr_pipeline = ASRFactory.create_asr_pipeline('faster_whisper', **asr_args)

    # synthesiser = pipeline("text-to-speech", "microsoft/speecht5_tts")
    #
    # embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
    # speaker_embedding = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)

    # Get device
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # List available ğŸ¸TTS models
    print(TTS().list_models())

    # Init TTS
    tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)

    app.listen(6006)
    logging.info("sseæœåŠ¡å¯åŠ¨")
    tornado.ioloop.IOLoop.current().start()